{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from helpers import *\n",
    "#import coach_dicts\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Validation libraries\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, recall_score, balanced_accuracy_score, precision_score, precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# Display plots inside the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Ignore warning related to pandas_profiling\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Display all dataframe columns in outputs (it has 63 columns, which is wider than the notebook)\n",
    "# This sets it up to display with a horizontal scroll instead of hiding the middle columns\n",
    "pd.set_option('display.max_columns', 800) \n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_rows', 1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.environ.get(\"DATA_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"tkdc_leona_2021-03-01.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path + data, sep= \",\", low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_letter1 = df[[\"id\", \"letter_M1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_letter2 = df[[\"id\", \"letter_M2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_letter1.set_index(\"id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_letter2.set_index(\"id\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wortdict_1 = pd.read_csv(\"Words_SentiArt.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(:</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>):</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>/:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4ev*</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>:(</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18705</td>\n",
       "      <td>übriges</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18706</td>\n",
       "      <td>übst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18707</td>\n",
       "      <td>übte</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18708</td>\n",
       "      <td>übung*</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18709</td>\n",
       "      <td>üppig*</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18710 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            (:  Unnamed: 1  Unnamed: 2  Unnamed: 3  Unnamed: 4  Unnamed: 5  \\\n",
       "0      (;      NaN         NaN         NaN         NaN         NaN           \n",
       "1      ):      NaN         NaN         NaN         NaN         NaN           \n",
       "2      /:      NaN         NaN         NaN         NaN         NaN           \n",
       "3      4ev*    NaN         NaN         NaN         NaN         NaN           \n",
       "4      :(      NaN         NaN         NaN         NaN         NaN           \n",
       "...    ..       ..          ..          ..          ..          ..           \n",
       "18705  übriges NaN         NaN         NaN         NaN         NaN           \n",
       "18706  übst    NaN         NaN         NaN         NaN         NaN           \n",
       "18707  übte    NaN         NaN         NaN         NaN         NaN           \n",
       "18708  übung*  NaN         NaN         NaN         NaN         NaN           \n",
       "18709  üppig*  NaN         NaN         NaN         NaN         NaN           \n",
       "\n",
       "       Unnamed: 6  Unnamed: 7  Unnamed: 8  Unnamed: 9  Unnamed: 10  \\\n",
       "0     NaN         NaN         NaN         NaN         NaN            \n",
       "1     NaN         NaN         NaN         NaN         NaN            \n",
       "2     NaN         NaN         NaN         NaN         NaN            \n",
       "3     NaN         NaN         NaN         NaN         NaN            \n",
       "4     NaN         NaN         NaN         NaN         NaN            \n",
       "...    ..          ..          ..          ..          ..            \n",
       "18705 NaN         NaN         NaN         NaN         NaN            \n",
       "18706 NaN         NaN         NaN         NaN         NaN            \n",
       "18707 NaN         NaN         NaN         NaN         NaN            \n",
       "18708 NaN         NaN         NaN         NaN         NaN            \n",
       "18709 NaN         NaN         NaN         NaN         NaN            \n",
       "\n",
       "       Unnamed: 11  Unnamed: 12  \n",
       "0     NaN          NaN           \n",
       "1     NaN          NaN           \n",
       "2     NaN          NaN           \n",
       "3     NaN          NaN           \n",
       "4     NaN          NaN           \n",
       "...    ..           ..           \n",
       "18705 NaN          NaN           \n",
       "18706 NaN          NaN           \n",
       "18707 NaN          NaN           \n",
       "18708 NaN          NaN           \n",
       "18709 NaN          NaN           \n",
       "\n",
       "[18710 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wortdict_2 = pd.read_csv(\"LIWC.csv\", sep=\";\")\n",
    "wortdict_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wortdict_2 = wortdict_2.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "wordlist_2 = []\n",
    "for word in wortdict_2:\n",
    "    word = str(word)\n",
    "    if \"*\" in word:\n",
    "        wordlist_2.append(word[:-1])\n",
    "    else:\n",
    "        wordlist_2.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from happierfuntokenizing import emoticon_string, regex_strings\n",
    "from unicode_codes import EMOTICON_REGEXES, EMOJI_UNICODE, EMOJI_ALIAS_UNICODE, UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_regexes = {k.lower(): re.compile(v) for k, v in EMOTICON_REGEXES.items()}\n",
    "\n",
    "\n",
    "def removeNumeric(token):\n",
    "    # remove phone numbers\n",
    "    token = re.sub(r'((1-\\d{3}-\\d{3}-\\d{4})|(1 \\d{3} \\d{3} \\d{4})|(\\d{3} \\d{3} \\d{4})|(\\(\\d{3}\\) \\d{3}-\\d{4})|(\\d{3}-\\d{3}-\\d{4}))$', '', token)\n",
    "    # remove all numeric words\n",
    "    token = '' if token.isdigit() else token\n",
    "    # remove words with 2 successive digits\n",
    "    token = '' if re.search(r'\\d{2}', token) else token\n",
    "    return token\n",
    "\n",
    "def isEmojiOrEmoticon(token):\n",
    "    if any([v.match(token) for k,v in emoticon_regexes.items()]) or token in UNICODE_EMOJI:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_re = re.compile(r\"\"\"(%s)\"\"\" % \"|\".join(regex_strings), re.VERBOSE | re.I | re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_re = re.compile(regex_strings[1], re.VERBOSE | re.I | re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, preserve_case=False, use_unicode=True):\n",
    "        self.preserve_case = preserve_case\n",
    "        self.use_unicode = use_unicode\n",
    "\n",
    "    def tokenize(self, s):\n",
    "        \"\"\"\n",
    "        Argument: s -- any string or unicode object\n",
    "        Value: a tokenize list of strings; conatenating this list returns the original string if preserve_case=False\n",
    "        \"\"\"        \n",
    "        # Try to ensure unicode:\n",
    "        if self.use_unicode:\n",
    "            try:\n",
    "                s = str(s)\n",
    "            except UnicodeDecodeError:\n",
    "                s = str(s).encode('string_escape')\n",
    "                s = str(s)\n",
    "        # Fix HTML character entitites:\n",
    "        #s = self.__html2unicode(s)\n",
    "        #s = self.__removeHex(s)\n",
    "        # Tokenize:\n",
    "        words = word_re.findall(s)\n",
    "        #print words #debug\n",
    "        # Possible alter the case, but avoid changing emoticons like :D into :d:\n",
    "        if not self.preserve_case:            \n",
    "            words = list(map((lambda x : x if emoticon_re.search(x) else x.lower()), words))\n",
    "        \n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(preserve_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multSpace = re.compile(r'\\s\\s+')\n",
    "startSpace = re.compile(r'^\\s+')\n",
    "endSpace = re.compile(r'\\s+$')\n",
    "multDots = re.compile(r'\\.\\.\\.\\.\\.+') #more than four periods\n",
    "newlines = re.compile(r'\\s*\\n\\s*')\n",
    "\n",
    "def shrinkSpace(s):\n",
    "    \"\"\"turns multiple spaces into 1\"\"\"\n",
    "    s = multSpace.sub(' ',s)\n",
    "    s = multDots.sub('....',s)\n",
    "    s = endSpace.sub('',s)\n",
    "    s = startSpace.sub('',s)\n",
    "    s = newlines.sub(' <NEWLINE> ',s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for letter in df_letter1.columns[0]:\n",
    "    letter = re.split(\" \", letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_letter1 = df_letter1.applymap(lambda s:s.lower() if type(s) == str else s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_list_1 = []\n",
    "for letter in df_letter1[\"letter_M1\"]:\n",
    "    cleaned_words = []\n",
    "    if isinstance(letter, str):\n",
    "        cleaned_token = shrinkSpace(letter.strip())\n",
    "        words = tokenizer.tokenize(cleaned_token)\n",
    "\n",
    "        for w in words:\n",
    "            if removeNumeric(w) and (isEmojiOrEmoticon(w)or w.lower() in wordlist_2):\n",
    "                cleaned_words.append(w)\n",
    "\n",
    "    cleaned_list_1.append(cleaned_words)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_letter1[\"letter_M1\"] = cleaned_list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_letter2 = df_letter2.applymap(lambda s:s.lower() if type(s) == str else s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for letter in df_letter2.columns[0]:\n",
    "    letter = re.split(\" \", letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_list_2 = []\n",
    "for letter in df_letter2[\"letter_M2\"]:\n",
    "    cleaned_words = []\n",
    "    if isinstance(letter, str):\n",
    "        cleaned_token = shrinkSpace(letter.strip())\n",
    "        words = tokenizer.tokenize(cleaned_token)\n",
    "\n",
    "        for w in words:\n",
    "            if removeNumeric(w) and (isEmojiOrEmoticon(w)or w.lower() in wordlist_2):\n",
    "                cleaned_words.append(w)\n",
    "\n",
    "    cleaned_list_2.append(cleaned_words)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_letter2[\"letter_M2\"] = cleaned_list_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = path + \"letter1_cleaned.csv\"\n",
    "#df_letter1.to_csv(filename, encoding=\"utf-8\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = path + \"letter2_cleaned.csv\"\n",
    "#df_letter2.to_csv(filename, encoding=\"utf-8\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"letter_M1\"] = cleaned_list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"letter_M2\"] = cleaned_list_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_zwei = ['registration','studyVariant','coach','PRE_bdi1','PRE_bdi2',\n",
    "               'PRE_bdi3','PRE_bdi4','PRE_bdi5','PRE_bdi6','PRE_bdi7','PRE_bdi8','PRE_bdi9','PRE_bdi10',\n",
    "               'PRE_bdi11','PRE_bdi12','PRE_bdi13','PRE_bdi14','PRE_bdi15','PRE_bdi16','PRE_bdi17','PRE_bdi18',\n",
    "               'PRE_bdi19','PRE_bdi20','PRE_bdi21','POST_phqD1','POST_phqD2','POST_phqD3','POST_phqD4','POST_phqD5',\n",
    "               'POST_phqD6','POST_phqD7','POST_phqD8','POST_phqD9',\n",
    "               'PRE_phqS1','PRE_phqS2','PRE_phqS3','PRE_phqS4','PRE_phqS5','PRE_phqS6','PRE_phqS7',\n",
    "               'PRE_phqS8','PRE_phqS9','PRE_phqS10','PRE_phqD1','PRE_phqD2','PRE_phqD3','PRE_phqD4','PRE_phqD5',\n",
    "               'PRE_phqD6','PRE_phqD7','PRE_phqD8','PRE_phqD9', 'PRE_birth','PRE_sex','PRE_education',\n",
    "               'PRE_work','PRE_household','PRE_relation','PRE_residence','PRE_internet','PRE_height','PRE_weight',\n",
    "               'PRE_treatment','PRE_support','PRE_kPT','PRE_ill','PRE_sickleave','PRE_doc',\n",
    "               'PRE_neurol','PRE_selfhelp','PRE_counsel','PRE_therapy','PRE_med','PRE_hospital',\n",
    "            'PRE_eurohis1','PRE_eurohis2','PRE_eurohis3','PRE_eurohis4','PRE_eurohis5',\n",
    "               'PRE_eurohis6','PRE_eurohis7','PRE_eurohis8', 'TI_score','TI_bip1',\n",
    "               'TI_bip2','TI_MDE','TI_dyst','TI_F25','TI_F22','TI_F23',\n",
    "               'TI_F29','TI_MDE_vr','TI_MDE_tr','TI_HYP_vr','TI_MAN_vr','TI_medik','TI_rekrut','PRE_gad1',\n",
    "               'PRE_gad2','PRE_gad3','PRE_gad4','PRE_gad5','PRE_gad6','PRE_gad7', 'PRE_costa1', 'PRE_costa2', 'PRE_costa3',\n",
    "              'PRE_costa4', 'PRE_costa5', 'PRE_costa6', 'PRE_costa7', 'PRE_costa8', 'PRE_costa9', 'PRE_costa10', 'PRE_costa11',\n",
    "              'PRE_costa12', 'PRE_costa13', 'PRE_costa14', 'PRE_costa15', 'PRE_costa16', 'PRE_costa17', 'PRE_costa18',\n",
    "              'PRE_costa19', 'PRE_costa20', 'PRE_costa21', 'PRE_pathev1', 'PRE_pathev2', 'PRE_pathev3', 'PRE_pathev4',\n",
    "              'PRE_pathev5', 'PRE_pathev6', 'PRE_pathev7', 'PRE_pathev8', 'PRE_pathev9', 'PRE_pathev10', \n",
    "              'PRE_euheals1','PRE_euheals2','PRE_euheals3','PRE_ipqr1','PRE_ipqr2','PRE_ipqr3','PRE_ipqr4','PRE_ipqr5',\n",
    "               'PRE_ipqr6','PRE_ipqr7','PRE_ipqr8','PRE_ipqr9','PRE_ipqr10','PRE_ipqr11','PRE_ipqr12','PRE_ipqr13',\n",
    "               'PRE_ipqr14','PRE_ipqr15','PRE_ipqr16','PRE_ipqr17','PRE_ipqr18', 'PRE_bsss1','PRE_bsss2','PRE_bsss3',\n",
    "               'PRE_bsss4','PRE_bsss5','PRE_bsss6','PRE_bsss7','PRE_bsss8','PRE_bsss9','PRE_bsss10','PRE_bsss11',\n",
    "               'PRE_bsss12','PRE_bsss13','PRE_gpse1','PRE_gpse2','PRE_gpse3','PRE_gpse4','PRE_gpse5','PRE_gpse6',\n",
    "               'PRE_gpse7','PRE_gpse8','PRE_gpse9','PRE_gpse10','PRE_pvq1','PRE_pvq2','PRE_pvq3','PRE_pvq4','PRE_pvq5',\n",
    "               'PRE_pvq6','PRE_pvq7','PRE_pvq8','PRE_pvq9','PRE_pvq10','PRE_pvq11','PRE_pvq12','PRE_pvq13','PRE_pvq14',\n",
    "               'PRE_pvq15','PRE_pvq16','PRE_pvq17','PRE_pvq18','PRE_pvq19','PRE_pvq20','PRE_pvq21', 'PRE_imet1','PRE_imet2','PRE_imet3','PRE_imet4','PRE_imet5','PRE_imet6','PRE_imet7',\n",
    "                'PRE_imet8','PRE_imet9','PRE_imet10', 'M1_phqD1','M1_phqD2','M1_phqD3','M1_phqD4','M1_phqD5','M1_phqD6',\n",
    "               'M1_phqD7','M1_phqD8','M1_phqD9', 'letter_M1', 'letter_M2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short = df[column_zwei]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short[\"letter_M1\"] = df_short[\"letter_M1\"].apply(lambda x:np.nan if len(x) ==0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion_cols = [\"TI_F29\", \"TI_F23\", \"TI_F22\", \"TI_F25\"]\n",
    "df_short.drop(exclusion_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short[\"letter_M2\"] = df_short[\"letter_M2\"].apply(lambda x:np.nan if len(x) ==0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short = df_short[df_short[[\"letter_M1\", \"letter_M2\"]].notnull().all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
